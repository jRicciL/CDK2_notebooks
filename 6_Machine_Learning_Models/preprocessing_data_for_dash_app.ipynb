{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(context='notebook', style = 'whitegrid', font_scale = 1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')\n",
    "from modules.plotting_metrics import PlotMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_name = 'cdk2'\n",
    "# Este es el DF que no tiene aun afgregados los valores AUC de las conformaciones\n",
    "path_to_json_file = glob.glob((os.path.join('..', 'data', \n",
    "                        F'TABLA_MTDATA_{prot_name.upper()}_*_crys_LIGS_INFO_LABELS.json')))[0]\n",
    "                      \n",
    "df_prot = pd.read_json(path_to_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract just the interesting features\n",
    "df_prot.columns\n",
    "columns_ = ['Labels_conf', 'Inhib', 'Inhib_mass']\n",
    "df_CDK2 = df_prot[columns_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MDS info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the MDS resutls\n",
    "import pickle\n",
    "\n",
    "# Pocket MDS\n",
    "path_mds_obj_pk = os.path.join('..', 'data', 'trajectory_analysis', 'cMDS_Pocket_402_obj.pyobj')\n",
    "with open(path_mds_obj_pk, 'rb') as f:\n",
    "    mds_pocket_402 = pickle.load(f)\n",
    "    \n",
    "# Pisani MDS\n",
    "path_mds_obj = os.path.join('..', 'data', 'trajectory_analysis', 'cMDS_Pisani_402_obj.pyobj')\n",
    "with open(path_mds_obj, 'rb') as f:\n",
    "    mds_pisani_402 = pickle.load(f)\n",
    "    \n",
    "a = mds_pisani_402[0][:2]\n",
    "b = mds_pocket_402[0][:2]\n",
    "\n",
    "c = np.concatenate((a, b))\n",
    "\n",
    "np.savetxt('./mds_subspaces_pis_pk.csv', c, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "%run ./helper_functions_S6.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_type = 'Dk_lef'\n",
    "df_swarm_dklef = pd.DataFrame()\n",
    "\n",
    "for db_name in scores_dic:\n",
    "    _X = scores_dic[db_name][score_type]['X']\n",
    "    _y = scores_dic[db_name][score_type]['y']\n",
    "    auc_scores = _X.apply(lambda x: roc_auc_score(y_true =_y, \n",
    "                                  y_score = -1 * x), axis = 0)\n",
    "    score_type_ = score_type.lower().replace('_', '')\n",
    "    df_swarm_dklef[db_name + '_vrd_' + score_type_] = auc_scores\n",
    "\n",
    "score_type = 'Dk_sc'\n",
    "df_swarm_dksc = pd.DataFrame()\n",
    "\n",
    "for db_name in scores_dic:\n",
    "    _X = scores_dic[db_name][score_type]['X']\n",
    "    _y = scores_dic[db_name][score_type]['y']\n",
    "    auc_scores = _X.apply(lambda x: roc_auc_score(y_true =_y, \n",
    "                                  y_score = -1 * x), axis = 0)\n",
    "    score_type_ = score_type.lower().replace('_', '')\n",
    "    df_swarm_dksc[db_name + '_vrd_' + score_type_] = auc_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.concat([df_CDK2, df_swarm_dksc, df_swarm_dklef], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to_csv('./df_pdb_cdk2_features_and_scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consensus Scorings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans or random\n",
    "# Consensus type\n",
    "# Docking score\n",
    "# Database\n",
    "\n",
    "# Save each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ = '../data/ml_evaluations/consensus_scoring/'\n",
    "\n",
    "# Each final csv goint to have the \n",
    "# consensus values, and databases\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ('kmeans', 'rfe')\n",
    "cons_list_names = ['Rbn', 'Rbs', 'Rbr', 'Rbv_*2', 'Rexp*2']\n",
    "inner_keys = ['pisani', 'pocket']\n",
    "\n",
    "final_list = []\n",
    "\n",
    "for method in methods:\n",
    "    for cons in cons_list_names:\n",
    "        file = glob(F'{path_}*{method}*{cons}*')[0]\n",
    "\n",
    "        with open(file, 'rb') as f:\n",
    "            dict_auc = pickle.load(f)\n",
    "        # iterate over the keys\n",
    "        for key in dict_auc.keys():\n",
    "            # for kmeans we currently have pisani and pocket\n",
    "            for in_key in inner_keys:\n",
    "                if method == 'kmeans':\n",
    "                    _in_key = '-' + in_key.lower()\n",
    "                    list_values = dict_auc[key][in_key].tolist()\n",
    "                elif method == 'rfe':\n",
    "                    _in_key = ''\n",
    "                    list_values = dict_auc[key]['rfe'].tolist()\n",
    "                names = key.split('_')\n",
    "                # Get the databaseName\n",
    "                db = names[0]\n",
    "                # Get the score type\n",
    "                score = names[1]\n",
    "\n",
    "                # Append new elemnts at the begining of the list\n",
    "                # Scoring > MethodFeature > DB > Consensus > Values\n",
    "                list_values.insert(0, cons.lower())\n",
    "                list_values.insert(0, db.lower())\n",
    "                list_values.insert(0, (method + _in_key).lower())\n",
    "                list_values.insert(0, score.lower())\n",
    "                final_list.append( list_values )\n",
    "                if method == 'kmeans': continue\n",
    "                else: break\n",
    "# Save the file\n",
    "file_name = './kmeans_cosensus_scorings.csv'\n",
    "df_ = pd.DataFrame(final_list).round(3)\n",
    "df_.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
