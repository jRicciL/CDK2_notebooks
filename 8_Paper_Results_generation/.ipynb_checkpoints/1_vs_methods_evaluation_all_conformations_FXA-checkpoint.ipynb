{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%run ../modules/plotting_metrics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memoization import cached\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold-out and Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '../6_Machine_Learning_Models/df_DkSc_results_COCRYS_CSAR_DEKOIS_DUD.pkl'\n",
    "X_merged_dksc = pd.read_pickle(file_name)\n",
    "y_true_merged = X_merged_dksc['activity']\n",
    "X_merged_dksc = X_merged_dksc.drop('activity', axis=1)\n",
    "X_merged_dksc.shape\n",
    "\n",
    "# Simplify the names\n",
    "X = X_merged_dksc.values\n",
    "y = y_true_merged.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_swarm_metrics(df_results, metric_name):\n",
    "    sns.set(context='talk', style='whitegrid', font_scale=0.8)\n",
    "    \n",
    "    df_melted = pd.melt(df_results.loc[metric_name], var_name='method', value_name=metric_name)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12,6))\n",
    "    ax = sns.swarmplot(data=df_melted, x='method', y=metric_name,\n",
    "                      size=6)\n",
    "    sns.pointplot(data=df_melted, x='method', y=metric_name, dodge=True,\n",
    "                  ci=95, ax=ax, join=False, color='black', capsize=0.4)\n",
    "    ax.set(\n",
    "           xlabel='VS Method')\n",
    "    ax.set_title(f'ML vs CS results: {metric_name.replace(\"_\", \" \").upper()}', \n",
    "                 fontweight='bold', fontsize=18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas styler\n",
    "def _col_sig_p_values(val):\n",
    "    color = 'red' if val < 0.05 else 'none'\n",
    "    return 'color: %s' % color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normality and Homocedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro, bartlett, levene\n",
    "\n",
    "def norm_test(x, alpha=0.05):\n",
    "    s, p = shapiro(x)\n",
    "    result = 'rejected' if p < alpha else 'accepted'\n",
    "    print(f'The H0 is {result} => (W={round(s, 3)}, p={round(p, 3)})')\n",
    "    \n",
    "def homovar_test(x, y, alpha=0.05):\n",
    "    s, p = bartlett(x, y)\n",
    "    result = 'rejected' if p < alpha else 'accepted'\n",
    "    print(f'The H0 is {result} => (W={round(s, 3)}, p={round(p, 3)})')\n",
    "    \n",
    "def multi_norm_test(df, metric='roc_auc', alpha=0.05):\n",
    "    res = df.loc[metric].apply(shapiro, axis=0)\n",
    "    return pd.DataFrame([0 if i[1] < alpha else 1 for i in res], \n",
    "             index=df.columns, columns=['Normality']).T\n",
    "\n",
    "def multi_homovar_test(df, metric='roc_auc', alpha=0.05, as_df=True):\n",
    "    res = bartlett(*cv5x2.loc[metric].values)\n",
    "    if as_df:\n",
    "        res = pd.DataFrame(res, columns=['Bartlett'], \n",
    "                           index=['statistic', 'p']).T\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers and consensus Scorings\n",
    "### ML Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "hyparams = {'strategy': \"stratified\"}\n",
    "dclf = DummyClassifier(**hyparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "hyparams ={'n_neighbors': 1, 'n_jobs': 4}\n",
    "knn = KNeighborsClassifier(**hyparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "hyparams = {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs', 'max_iter':400}\n",
    "lr = LogisticRegression(**hyparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "hyparams ={'subsample': 0.5, 'n_estimators': 200, \n",
    "           'max_depth': 20, 'learning_rate': 0.05, \n",
    "           'gamma': 0.01, 'colsample_bytree': 0.5, 'alpha': 0.01}\n",
    "xgb = XGBClassifier(**hyparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "hyparams = {'n_estimators': 100, 'min_samples_split': 10,\n",
    "            'min_samples_leaf': 4, \n",
    "            'max_features': 'sqrt', 'max_depth': 10}\n",
    "rf = RandomForestClassifier(**hyparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Classifier\n",
    "ml_classifiers = {\n",
    "    'dclf': dclf,\n",
    "    'knn': knn,\n",
    "    'lr': lr,\n",
    "    'xgb': xgb,\n",
    "    'rf': rf\n",
    "}\n",
    "\n",
    "# update names\n",
    "ml_classifiers = {f'ml_{name}': clf \n",
    "                for name, clf in ml_classifiers.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consensus Scorings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../6_Machine_Learning_Models/5_Helper_Consensus_Scoring.ipynb\n",
    "\n",
    "cs_functions = {\n",
    "    'MEAN': get_mean_score,\n",
    "    'MAX': get_max_score,\n",
    "    'MIN': get_min_score,\n",
    "    'VOTE': get_vote_score,\n",
    "    'RANK': get_rank_score \n",
    "}\n",
    "\n",
    "# update names\n",
    "cs_functions = {f'cs_{name}': func \n",
    "                for name, func in cs_functions.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimators dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = {**ml_classifiers, **cs_functions}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./1_Helper_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=dict(roc_auc = {'metric_name': 'roc_auc'},\n",
    "             nef_02 = {'metric_name': 'ef', \n",
    "                    'fraction': 0.02, 'method':'normalized'},\n",
    "             nef_005 = {'metric_name': 'ef', \n",
    "                    'fraction': 0.005, 'method':'normalized'},\n",
    "             nef_12_Ra = {'metric_name': 'ef', \n",
    "                    'fraction': 0.12, 'method':'normalized'}\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(18, 7))\n",
    "plot_roc_cv(lr, X, y, name='Log Reg', ax=ax[0], random_state=42)\n",
    "plot_roc_cv(xgb, X, y, name='XGB', ax=ax[1], random_state=42)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 folds/reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cv5 = k_cross_validation(estimators, X, y, \n",
    "                             metrics=metrics,\n",
    "                             n_splits=5, random_state=42)\n",
    "\n",
    "metric='roc_auc'\n",
    "# Normality\n",
    "display(multi_norm_test(cv5, metric=metric))\n",
    "# Homocedasticity\n",
    "display(multi_homovar_test(cv5, metric=metric))\n",
    "\n",
    "cv5.loc[metric]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hold-out validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ho5 = n_hold_out_validation(estimators, X, y, metrics=metrics, \n",
    "                      n_reps=5, random_state=42)\n",
    "metric='roc_auc'\n",
    "# Normality\n",
    "display(multi_norm_test(ho5, metric=metric))\n",
    "# Homocedasticity\n",
    "display(multi_homovar_test(ho5, metric=metric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15 folds/reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cv15 = k_cross_validation(estimators, X, y, \n",
    "                             metrics=metrics,\n",
    "                             n_splits=15, random_state=42)\n",
    "\n",
    "metric='roc_auc'\n",
    "plot_swarm_metrics(cv15, metric_name=metric)\n",
    "# Normality\n",
    "display(multi_norm_test(cv15, metric=metric))\n",
    "# Homocedasticity\n",
    "display(multi_homovar_test(cv15, metric=metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ho15 = n_hold_out_validation(estimators, X, y, metrics=metrics, \n",
    "                      n_reps=15, random_state=42)\n",
    "\n",
    "metric='roc_auc'\n",
    "plot_swarm_metrics(ho15, metric_name=metric)\n",
    "# Normality\n",
    "display(multi_norm_test(ho15, metric=metric))\n",
    "# Homocedasticity\n",
    "display(multi_homovar_test(ho15, metric=metric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5x2 CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cv5x2 = nk_rep_cross_validation(estimators, X, y, metrics=metrics, \n",
    "                      n_splits=2, n_repeats=5, random_state=42)\n",
    "\n",
    "metric='roc_auc'\n",
    "plot_swarm_metrics(cv5x2, metric_name=metric)\n",
    "# Normality\n",
    "display(multi_norm_test(cv5x2))\n",
    "# Homocedasticity\n",
    "display(multi_homovar_test(cv5x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cv5x2 = nk_rep_cross_validation(estimators, X, y, metrics=metrics, \n",
    "                      n_splits=2, n_repeats=5, random_state=42)\n",
    "\n",
    "metric='nef_12_Ra'\n",
    "plot_swarm_metrics(cv5x2, metric_name=metric)\n",
    "# Normality\n",
    "display(multi_norm_test(cv5x2, metric=metric))\n",
    "# Homocedasticity\n",
    "display(multi_homovar_test(cv5x2, metric=metric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple samples\n",
    "- one-way ANOVA with repeated measures\n",
    "- Friedman's ANOVA\n",
    "- Cochran's Q test\n",
    "- Binomial $\\chi^2$ with Bonferroni correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-way ANOVA with repeated measures\n",
    "\n",
    "$H_0$: $\\mu_1 = \\mu_2 = ... = \\mu_m$   \n",
    "$H_a$: $\\mu_i \\neq \\mu_j$, for at least one pair $i,j$ of the methods.\n",
    "\n",
    "##### post hoc Tucket HSD\n",
    "$H_0$: $\\mu_i = \\mu_j, \\forall i \\neq j$   \n",
    "$H_a$: $\\mu_i \\neq \\mu_j,  \\forall i \\neq j$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from scipy.stats import f_oneway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cv5x2.loc['roc_auc']\n",
    "df = df.drop('ml_dclf', axis=1)\n",
    "n, m = df.shape\n",
    "\n",
    "f = pd.melt(df, var_name='clf', value_name='score')\n",
    "f['rep'] = np.tile(range(1, n + 1), m)\n",
    "\n",
    "\n",
    "print(AnovaRM(data=f, depvar='score', subject='rep', within=['clf'], aggregate_func='mean').fit())\n",
    "\n",
    "print(statsmodels.stats.multicomp.pairwise_tukeyhsd(endog=f['score'], groups=f['clf'], alpha=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_oneway(*df.values.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "lm = ols('score ~ C(clf) + C(rep)', data=f).fit()\n",
    "# print(lm.summary())\n",
    "table = sm.stats.anova_lm(lm, typ=2) \n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-parametric: Friedman's ANOVA for repeated measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "friedmanchisquare(*df.values.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### post hocs\n",
    "\n",
    "#### Wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikit_posthocs as sp\n",
    "\n",
    "sp.posthoc_conover(f, val_col='score', group_col='clf').style.applymap(_col_sig_p_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nemenyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.posthoc_nemenyi_friedman(df).style.applymap(_col_sig_p_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Samples\n",
    "- Delong\n",
    "- Nedeau\n",
    "- Wilcoxon\n",
    "- Bootstrap\n",
    "- paired t-test\n",
    "- McNemar\n",
    "- 5x2cv F modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_res = ho15.loc['roc_auc','ml_xgb']\n",
    "knn_res = ho15.loc['roc_auc','ml_knn']\n",
    "\n",
    "# Normalidad\n",
    "norm_test(xgb_res)\n",
    "norm_test(knn_res)\n",
    "\n",
    "# Homogeneidad de varianzas\n",
    "homovar_test(xgb_res, knn_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from mlxtend.evaluate import combined_ftest_5x2cv\n",
    "\n",
    "f, p = combined_ftest_5x2cv(\n",
    "        estimator1=estimators['ml_xgb'],\n",
    "        estimator2=estimators['ml_knn'],\n",
    "        X=X, y=y,\n",
    "        scoring='roc_auc',\n",
    "        random_seed=42\n",
    "    )\n",
    "\n",
    "print('F statistic: %.3f' % f)\n",
    "print('p value: %.3f' % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, p = combined_ftest_5x2cv(\n",
    "        estimator1=estimators['ml_xgb'],\n",
    "        estimator2=estimators['ml_lr'],\n",
    "        X=X, y=y,\n",
    "        scoring='roc_auc',\n",
    "        random_seed=42\n",
    "    )\n",
    "\n",
    "print('F statistic: %.3f' % f)\n",
    "print('p value: %.3f' % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_error(x):\n",
    "    return np.std(x)/np.sqrt(len(x) - 1)\n",
    "\n",
    "standard_error(cv15.loc['roc_auc','ml_xgb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def mean_confidence_interval(x, confidence=0.95):\n",
    "    n = len(x)\n",
    "    mean, se = np.mean(x), stats.sem(x)\n",
    "    d = se * stats.t.ppf((1 + confidence)/2, n - 1)\n",
    "    return mean - d, mean + d\n",
    "\n",
    "a = cv15.loc['roc_auc','ml_xgb']\n",
    "mean_confidence_interval(a)\n",
    "\n",
    "sns.tsplot(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, scipy.stats as st\n",
    "\n",
    "st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
